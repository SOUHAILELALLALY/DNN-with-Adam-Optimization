# DNN-with-Adam-Optimization
# Deep Neural Network with Adam Optimization for CIFAR10 Classification

## Overview

Ce projet vise à développer et entraîner un réseau de neurones profonds (DNN) pour la classification des images du jeu de données CIFAR10. Le DNN est optimisé en utilisant l'algorithme d'optimisation Adam, qui est une variante de la descente de gradient stochastique. Le jeu de données CIFAR10 contient 60 000 images couleur de 32x32 réparties en 10 classes, avec 6 000 images par classe.

## Objectifs

- **Prétraitement des données** : Charger et prétraiter les données du jeu CIFAR10, y compris la normalisation et le redimensionnement.
  
- **Initialisation du réseau** : Définir et initialiser l'architecture du réseau de neurones profonds avec des couches cachées.

- **Optimisation avec Adam** : Implémenter l'algorithme d'optimisation Adam pour accélérer l'apprentissage et améliorer la convergence du réseau.

- **Entraînement du réseau** : Effectuer la propagation avant et la propagation arrière pour entraîner le réseau sur les données d'entraînement.

- **Évaluation et visualisation** : Évaluer les performances du modèle sur l'ensemble de test et visualiser les résultats à l'aide de graphiques.

## Technologies utilisées

- Python
- NumPy
- Matplotlib
- Scikit-learn
- PyTorch (torchvision)

## Conclusion

Ce projet illustre l'application de techniques avancées de deep learning et d'optimisation pour résoudre un problème de classification d'images. L'utilisation de l'algorithme Adam permet d'améliorer l'efficacité de l'apprentissage et de réduire le temps nécessaire pour obtenir de bonnes performances sur le jeu de données CIFAR10.
